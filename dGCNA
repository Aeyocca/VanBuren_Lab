Welp I just lost the notes for the last few days because I didn't save the file and closed it.. lesson learned
Not too big of a deal, I can recreate the error message from yesterday its not necessary, just shows that I need to update the compiler from version 6 to version 7.. but thats a big problem I guess, maybe should email someone from hpcc as last resort, tried just downloading java software but that isn't working, maybe can install for cygwin environment.. we shall see

10-26-17
Try to summarize notes that were lost because they were not saved:
java is complicated
All the .java files seem to be part of a package called networkCalcPackage as they all have that as the first line. It seems Operations.java is the only one that doesn't depend on other scripts so far, but if I find out it does, will have another problem.
I have all the .java scripts on hpcc
I uploaded all other required packages and pointed to them using:
$ export CLASSPATH=${CLASSPATH}:${package .jar file}


Sweet. List of exports needed:
[yoccaala@dev-intel14 01_VanBuren]$ export CLASSPATH=${CLASSPATH}:.
[yoccaala@dev-intel14 01_VanBuren]$ export CLASSPATH=${CLASSPATH}:commons-lang3-3.6.jar
[yoccaala@dev-intel14 01_VanBuren]$ export CLASSPATH=${CLASSPATH}:commons-math3-3.6.1.jar
[yoccaala@dev-intel14 01_VanBuren]$ export CLASSPATH=${CLASSPATH}:commons-cli-1.4.jar
[yoccaala@dev-intel14 01_VanBuren]$ export CLASSPATH=${CLASSPATH}:jcommon-1.0.23.jar
[yoccaala@dev-intel14 01_VanBuren]$ export CLASSPATH=${CLASSPATH}:jfreechart-1.0.19.jar

Now we got some jar files that are all dependent on each other. Lets try

$ javac *.java
I think it worked, got all .class files, but also got OperationsS1 and S2 .class. Not sure what this is. Additionally got the following error: has additional uses or overrides of a deprecated API
Looked it up, said I'm just using outdated things which Seems like program could still run so I'm going to roll with it

$ java NetworkCalculator determine -d Sedum_RNAseq_TPM-v3.0.1-average.txt -c pcc -aL 2 -aH 8 -mL 0.1 -mH 0.9
 Could not find or load main class NetworkCalculator

Its looking better, moved all .java and .class files to directory, directly above that directory I got all the package .jar files,
$ java networkCalcPackage.NetworkCalculator -determine
usage: java -jar jarfile.jar
 -compare <compare>         compare several network matricies
 -construct <construct>     construct a network via application of a
                            topological overlap calculation
 -determine <determine>     Determine best parameters for dataset
 -h                         print this message
 -permute <permute>         perform background permutations to determine
                            significance cutoff
 -scalefree <scalefree>     Determine elasticity cutoff via conformation
                            to scale free criteria
 -similarity <similarity>   construct a similarity matrix and print it to
                            a file
 -test <test>               test routines

$ java networkCalcPackage.NetworkCalculator determine -d ../../Sedum_RNAseq_TPM-v3.0.1-average.txt -c pcc -aL 2 -aH 8 -mL 0.1 -mH 0.9 -t 1
data file is not a rectilinear data file

Check Sedum file

Boooo, I'm getting it to run o shit!!!! I think I can just remove second gene column, hold up though, going to let it run and see what happens, not sure how we will get to specify which series of treatments to look at
Seems like optimum input file format is gene names in first column and treatments in all the rest

Killed the job, would take forever running on command line to try all combos to determine parameters, Submit bash shell for that, 4:00:00 walltime to start, 6 Gb mem walltime=4:00:00,nodes=1:ppn=3,feature='intel14|intel16',mem=6gb
Just submit as is, may have memory problems but we will get there when we get there

$ qsub qsub_network_determine
48664920.mgr-04.i
48665103.mgr-04.i

request 50 Gb mem

What kind of output is this? How will this tell me my optimum parameters?
Scale Free Criterion:
Correlation to Log-Log model
,2.0,4.0,6.0,8.0
0.1,0.0,0.0,0.0,0.0
0.15,0.0,0.0,0.0,0.0
0.2,0.0,0.0,0.0,0.0
0.25,0.0,0.0,0.0,0.0
0.3,0.0,0.0,0.0,0.0
0.35,0.0,0.0,0.0,0.0
0.4,0.0,0.0,0.0,0.0
0.45,0.0,0.0,0.0,0.0
0.5,0.0,0.0,0.0,0.0
0.55,0.0,0.0,0.0,0.0
0.6,0.0,0.0,0.0,0.0
0.65,0.0,0.0,0.0,0.136
0.7,0.0,0.0,0.0,0.19
0.75,0.0,0.0,0.0,0.2
0.8,0.0,0.0,0.007,0.156
0.85,0.0,0.0,0.32,0.041


Regression Slope:
,2.0,4.0,6.0,8.0
0.1,NaN,NaN,NaN,NaN
0.15,NaN,NaN,NaN,NaN
0.2,NaN,NaN,NaN,NaN
0.25,NaN,NaN,NaN,NaN
0.3,NaN,NaN,NaN,NaN
0.35,NaN,NaN,NaN,NaN
0.4,NaN,NaN,NaN,NaN
0.45,NaN,NaN,NaN,NaN
0.5,NaN,NaN,NaN,NaN
0.55,NaN,NaN,NaN,NaN
0.6,NaN,NaN,NaN,NaN
0.65,NaN,NaN,NaN,-2.1641193989891176
0.7,NaN,NaN,NaN,1.7852142895527472
0.75,NaN,NaN,NaN,1.2242102459770012
0.8,NaN,NaN,-0.6982692582149397,0.8374463347670197
0.85,NaN,NaN,2.985578009627139,0.30994682792680694


Mean node connectivity
,2.0,4.0,6.0,8.0
0.1,25122.406,27192.646,28470.607,29229.588
0.15,24070.496,25303.865,25957.64,26238.559

fuck it, run with alpha = 20, mu = 0.8

java networkCalcPackage.NetworkCalculator construct -d sedum_fixed_cut.txt -a 20 -c pcc -m 0.8 -o ./tmp -t 1 -M 0
48685141.mgr-04.i
walltime exceeded (had requested 4 hours)

Alrighty, new information:
Need to have two separate data frames, one for each treatment (C3 and CAM), run determine on both (run script twice), run construct on both (run script twice i think check help options again), run compare together, for the compare command, I believe you just point to the directory that contains the output from construct. That would make sense but not specified in help options
Split the dataframes first:

module load powertools
dev 
# random dev. node for testing (< 4 hrs)

haha, just like ssh to dev node, he mentioned you can request a certain number of cores or something, I don't remember how, check out hpcc wiki

[yoccaala@dev-intel16-k80 src]$ java networkCalcPackage.NetworkCalculator construct
usage: java -jar jarfile.jar
 -a <alpha>         alpha parameter for sigmoid adjacency calculation
                    (i.e. 20)
 -c <correlation>   correlation metric to use ('gini','pcc','spearman')
 -d <datafile>      Data frame, tab delimited, with header, of per-gene,
                    per-condition expression values
 -h                 print this message
 -m <mu>            mu parameter for sigmoid adjacency calculation (i.e.
                    0.8)
 -M <Mask>          parameter for masking matricies - values below this
                    will be set to zero
 -o <output>        Temporary Directory
 -t <threads>       Number of Compute Threads
 
 $java networkCalcPackage.NetworkCalclator construct -d sedum_C3.txt -c pcc -a 20 -m 0.8 -M 0 -o ./tmp -t 5


Change walltime and ppn reqs: #PBS -l walltime=30:00:00,nodes=1:ppn=8,feature='intel14|intel16',mem=50gb
[yoccaala@dev-intel16-k80 src]$ qsub qsub_network_construct_C3
48716754.mgr-04.i
[yoccaala@dev-intel16-k80 src]$ qsub qsub_network_construct_CAM
48716757.mgr-04.i

30 hr walltime exceeded, bump ppn=16 and walltime=120:00:00
C3
48839861.mgr-04.i
CAM
48839862.mgr-04.i
48933432.mgr-04.i

Submitted about 30 hrs ago, still queued (sp?)

11-06-17

Those jobs still were not running so I submitted another one requesting 50 hr walltime instead of 120 hrs., but delete those since I did not change what directory they write the output to so would just overwrite the other runs and may change something.

Jennifer told me instead of requesting 16 CPUs on 1 node, split it across 8 nodes with 2 CPUs from each node, keep the 50 hr walltime request, change the output directory to tmp_C3_cut and tmp_CAM_cut
C3:
49117688.mgr-04.i

CAM:
[yoccaala@gateway-03 src]$ qsub qsub_network_construct_CAM_cut
49117692.mgr-04.i


11-07-17

These jobs created an Adjacency.cytoscape.raw.tab file that was 73 Gb for C3 at one point, I only have 50 Gb allocated to me, so that filled up pretty quickly, I think the job may have stopped running. Anyway, if disk quota is exceeded, cannot simply rm files, so consulted this website: https://www.bfg.uni-freiburg.de/doc/bwgrid/bwgrid-faq/deleting-files-when-quota-exceeded which told me to do this:
$ cp /dev/null $FILENAME #Makes file empty it seems
$ rm $FILENAME

Did this for both tmp_C3_cut and tmp_CAM_cut, then emptied those two folders, fill out a quota increase request form for 400 Gb just incase they get too big: hpcc: https://contact.icer.msu.edu/quota
If that is denied or for some reason I need more space, ask Bob if he has / can request scratch space or /mnt/research space: https://wiki.hpcc.msu.edu/display/hpccdocs/HPCC+File+Systems
"Thank you - your ticket number 32426 was created". Expect reply within 1-2 business days

Request accepted!!!
[yoccaala@dev-intel14 src]$ qsub qsub_network_construct_C3_cut
49186923.mgr-04.i
[yoccaala@dev-intel14 src]$ qsub qsub_network_construct_Cam_cut
qsub: script file 'qsub_network_construct_Cam_cut' cannot be loaded - No such file or directory
[yoccaala@dev-intel14 src]$ qsub qsub_network_construct_CAM_cut
49186930.mgr-04.i

11-19-17
C3 cut1 finished yesterday! lets check it out, this is what I ran it with #PBS -l walltime=140:00:00,nodes=8:ppn=2,feature='intel14|intel16',mem=50gb
in tmp_C3_cut1 directory, got a Cluster/ directory with 189 different cluster txt files hopefully with gene IDs, lets see, YAWWWWWWWWWWWWWWWWWWWWWWWWW, finally making progress with this after like two weeks which is exciting, but probably have to put on backburner with proposal and test coming up..... pretting exciting though for later

I dont think CAM construct worked so submit that:
[yoccaala@dev-intel14 src]$ qsub qsub_network_construct_CAM_cut1
49629672.mgr-04.i
fix directories really quick:
[yoccaala@dev-intel14 src]$ qsub qsub_network_construct_CAM_cut1
49631526.mgr-04.i


11-28-17
my good directories are tmp_C3_cut1 and tmp_CAM_cut1
Next step after construct: compare I believe

module load Java/jdk1.8.0

export CLASSPATH=${CLASSPATH}:.
export CLASSPATH=${CLASSPATH}:commons-lang3-3.6.jar
export CLASSPATH=${CLASSPATH}:commons-math3-3.6.1.jar
export CLASSPATH=${CLASSPATH}:commons-cli-1.4.jar
export CLASSPATH=${CLASSPATH}:jcommon-1.0.23.jar
export CLASSPATH=${CLASSPATH}:jfreechart-1.0.19.jar

[yoccaala@dev-intel16-k80 src]$ java networkCalcPackage.NetworkCalculator compare
usage: java -jar jarfile.jar
 -c <correlation>      correlation metric used for both networks
 -e1 <expression1>     Expression Frame for Network 1
 -e2 <expression2>     Expression Frame for Network 2
 -h                    print this message
 -MN <negativeMask>    Negative cutoff for elasticity network - default
                       -0.01
 -MP <positiveMask>    positive cutoff for elasticity network - default
                       0.01
 -na <negativeAlpha>   alpha for negative differential adjacency
                       calculation
 -nm <negativeMu>      mu for negative differential adjacency calculation
 -o <output>           output file
 -pa <positiveAlpha>   alpha for positive differential adjacency
                       calculation
 -pm <positiveMu>      mu for positive differential adjacency calculation
 -t <threads>          number of processing threads

Why the hell did I run construct if I am not going to do anything with those using the compare command? o whale, moo ve on, just go ahead and run comare on the command line first to make sure its running then submit job

[yoccaala@dev-intel16-k80 src]$ java networkCalcPackage.NetworkCalculator compare -c pcc -e1 sedum_C3.txt -e2 sedum_CAM.txt -o compare_test.txt -na 0.05 -nm 0 -pa 0.05 -pm 0 -t 4

No idea what to put for the positive / negative alpha / mu values. Left both as 0.05 and 0 respectively. Since I have so many nodes and ppn, leave threads at 1

[yoccaala@dev-intel16-k80 src]$ qsub qsub_network_compare_CAM
50042577.mgr-04.i

[yoccaala@dev-intel16-k80 src]$ qsub qsub_network_compare_CAM
50043463.mgr-04.i

Not sure why I added the CAM tag, it inputs both expression matricies

[yoccaala@dev-intel14 src]$ qsub qsub_network_compare_CAM
50044705.mgr-04.i
for the above submission, increased memory request to 60Gb and added -Xmx:50g to java command

Max heap size allowed by MSU hpcc is 32Gb, adjust and resubmit:
[yoccaala@dev-intel14 src]$ qsub qsub_network_compare_CAM
50047874.mgr-04.i

Try again with 30g
[yoccaala@dev-intel14 src]$ qsub qsub_network_compare_CAM
50049967.mgr-04.i
invalid max heap size again, try 15gigs I guess

[yoccaala@dev-intel14 src]$ qsub qsub_network_compare_CAM
50073841.mgr-04.i

need to start labeling what my suffixes are... what is the difference between regular and cut1, seems I had a successful run for both C3 and C3_cut1. according to the above, the only difference I see is that they are a separate run, will check qsubs to make sure, looks like the regular construct (without the cut1 suffix) may have been successful for C3 but not CAM so can just leave that one alone. Yea qsub scripts don't look any different except for output directory

15g also seems to be invalid max heap size, maybe the syntax is wrong, how the hell can construct run but not compare?
32 bit maximum is 4 Gb, I think this is 64, but screw it, set to 4 Gb and run while I think about how else to solve problem
[yoccaala@dev-intel14-k20 src]$ qsub qsub_network_compare_CAM
50094091.mgr-04.i

maybe the g is invalid, try running on command line down to 1 g, if g doesn't work, try 2048m (equal to 2 Gb) son of a bitch, I put -Xmx: with a colon. Its the colon thats invalid. Got it to start on command line with 30 Gb, so submit with 30 Gb

[yoccaala@dev-intel14-k20 src]$ qsub qsub_network_compare_CAM
50094184.mgr-04.i
